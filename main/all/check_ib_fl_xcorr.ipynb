{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import fibsem\n",
    "from fibsem.imaging import masks\n",
    "from fibsem.imaging import utils   \n",
    "from autoscript_sdb_microscope_client.structures import AdornedImage\n",
    "from PIL import Image\n",
    "import logging\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import ndimage as ndi\n",
    "from skimage.segmentation import watershed\n",
    "from skimage.feature import peak_local_max\n",
    "from skimage import data\n",
    "from skimage import filters\n",
    "from skimage.color import rgb2gray\n",
    "import imageio\n",
    "import cv2\n",
    "import glob\n",
    "import itertools\n",
    "import pandas as pd\n",
    "from pprint import pprint\n",
    "import plotly.express as px\n",
    "import scipy\n",
    "import statsmodels\n",
    "import ipywidgets\n",
    "from dataclasses import dataclass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def xcorr(\n",
    "    img1: np.ndarray, \n",
    "    img2: np.ndarray, \n",
    "    use_mask: bool = True, \n",
    "    use_threshold: bool = True) -> np.ndarray:\n",
    "\n",
    "    if img1.data.shape != img2.data.shape:\n",
    "        err = f\"Image 1 {img1.data.shape} and Image 2 {img2.data.shape} need to have the same shape\"\n",
    "        logging.error(err)\n",
    "        raise ValueError(err)\n",
    "\n",
    "    if use_mask:\n",
    "        # Create Fourier Transform WITH Bandpass Filter\n",
    "        pixelsize_img1 = img1.data.shape\n",
    "        pixelsize_img2 = img2.data.shape\n",
    "        img1_mask = masks.create_bandpass_mask(pixelsize_img1, 100, 4, 3)\n",
    "        img2_mask = masks.create_bandpass_mask(pixelsize_img2, 100, 4, 3)\n",
    "        img1fft = np.fft.ifftshift(img1_mask * np.fft.fftshift(np.fft.fft2(img1.data)))\n",
    "        img2fft = np.fft.ifftshift(img2_mask * np.fft.fftshift(np.fft.fft2(img2.data)))\n",
    "        assert img1_mask is not None, \"Mask1 can not be None when using a Mask\"\n",
    "        assert img2_mask is not None, \"Mask2 can not be None when using a Mask\"\n",
    "\n",
    "    else:\n",
    "        # Create Fourier Transform\n",
    "        img1fft = np.fft.ifftshift(np.fft.fftshift(np.fft.fft2(img1.data)))\n",
    "        img2fft = np.fft.ifftshift(np.fft.fftshift(np.fft.fft2(img2.data)))\n",
    "\n",
    "    # Do some shady normalization(?)\n",
    "    n_pixels1 = img1.data.shape[0] * img1.data.shape[1]\n",
    "    img1fft[0, 0] = 0\n",
    "    tmp = img1fft * np. conj(img1fft)\n",
    "    img1fft = n_pixels1 * img1fft / np.sqrt(tmp.sum())\n",
    "    \n",
    "\n",
    "    n_pixels2 = img2.data.shape[0] * img2.data.shape[1]\n",
    "    img2fft[0, 0] = 0\n",
    "    tmp = img2fft * np. conj(img2fft)\n",
    "    img2fft = n_pixels2 * img2fft / np.sqrt(tmp.sum())\n",
    "\n",
    "\n",
    "    if use_threshold:\n",
    "        # Create threshold (Otsu's method) in abs Space\n",
    "        abs1 = np.fft.fftshift(np.fft.ifftshift(np.fft.ifft2(img1fft)))\n",
    "        abs2 = np.fft.fftshift(np.fft.ifftshift(np.fft.ifft2(img2fft)))\n",
    "        otsu1 = filters.threshold_otsu(np.abs(abs1))\n",
    "        otsu2 = filters.threshold_otsu(np.abs(abs2))\n",
    "\n",
    "        # Create segmented binary Img\n",
    "        binary1 = (abs1 > otsu1)*1\n",
    "        binary2 = (abs2 > otsu2)*1\n",
    "        \n",
    "        # Back to Fourier Space for cross-correlation\n",
    "        fft1 = np.fft.ifftshift(np.fft.fftshift(np.fft.fft2(binary1)))\n",
    "        fft2 = np.fft.ifftshift(np.fft.fftshift(np.fft.fft2(binary2)))\n",
    "\n",
    "        # Cross-correlate the two images\n",
    "        corr = np.real(np.fft.fftshift(np.fft.ifft2(fft1 * np.conj(fft2))))\n",
    "\n",
    "        # Cross-correlation center and shift from center\n",
    "        maxX, maxY = np.unravel_index(np.argmax(corr), corr.shape)\n",
    "        cen = np.asarray(corr.shape) / 2\n",
    "        err = np.array(cen - [maxX, maxY], int)\n",
    "        valMax = np.amax(corr)\n",
    "        return corr, valMax, cen, err,\n",
    "\n",
    "    else:\n",
    "        # Cross-correlate the two images\n",
    "        corr = np.real(np.fft.fftshift(np.fft.ifft2(img1fft * np.conj(img2fft))))\n",
    "       \n",
    "        # Cross-correlation center and shift from center\n",
    "        maxX, maxY = np.unravel_index(np.argmax(corr), corr.shape)\n",
    "        cen = np.asarray(corr.shape) / 2\n",
    "        err = np.array(cen - [maxX, maxY], int)\n",
    "        valMax = np.amax(corr)\n",
    "        return corr, valMax, cen, err"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dictionary for IB images, sort by grid position, field with (img stack), and corresponding name/img position\n",
    "dict1 = {}\n",
    "dict2 = {}\n",
    "dict3 = {}\n",
    "grid_poses = [\"000.000\", \"000.001\", \"000.002\", \"001.000\", \"001.001\", \"001.002\", \"002.000\", \"002.001\", \"002.002\"]\n",
    "hfws = [\"8\", \"15\", \"20\", \"30\", \"50\"]\n",
    "names = [\"base\", \"diag_down\", \"diag_up\", \"start\"]\n",
    "\n",
    "for grid_pos in grid_poses:\n",
    "    dict1[grid_pos] = {}\n",
    "    dict2[grid_pos] = {}\n",
    "    for hfw in hfws:\n",
    "        dict1[grid_pos][hfw] = {}\n",
    "        dict2[grid_pos][hfw] = {}\n",
    "        for name in names:\n",
    "            fname1 = glob.glob(f\"../../mapping_2022-09-27.01-18-18PM/{grid_pos}/{name}*{hfw}*.tif\")[0]\n",
    "            fname2 = glob.glob(f\"../../mapping_2022-09-27.02-59-50PM/{grid_pos}/{name}*{hfw}*.tif\")[0]\n",
    "    \n",
    "            img1 = mpimg.imread(fname1)\n",
    "            img2 = mpimg.imread(fname2)\n",
    "            dict1[grid_pos][hfw][name] = img1\n",
    "            dict2[grid_pos][hfw][name] = img2\n",
    "\n",
    "for grid_pos in [\"000.000\", \"000.001\", \"001.000\", \"001.001\"]:\n",
    "    dict3[grid_pos] = {}\n",
    "    for hfw in hfws:\n",
    "        dict3[grid_pos][hfw] = {}\n",
    "        for name in names:\n",
    "            fname3 = glob.glob(f\"../../mapping_2022-09-27.04-26-12PM/{grid_pos}/{name}*{hfw}*.tif\")[0]\n",
    "            img3 = mpimg.imread(fname3)\n",
    "            dict3[grid_pos][hfw][name] = img3\n",
    "\n",
    "# Create dictionary for Fluorescence images, sort by grid position (tile) and exposure times\n",
    "# Additionally, transpose and crop the image array to the right IB image size.\n",
    "fluor1 = {}\n",
    "fluor2 = {}\n",
    "fluor3 = {}\n",
    "tiles = [\"0.0\", \"0.1\", \"0.2\", \"1.0\", \"1.1\", \"1.2\", \"2.0\", \"2.1\", \"2.2\"]\n",
    "exposures = [\"350\", \"500\"]\n",
    "for tile in tiles:\n",
    "    fluor1[tile] = {}\n",
    "    fluor2[tile] = {}\n",
    "    for exposure in exposures:\n",
    "        file1 = glob.glob(f\"../../mapping_2022-09-27.01-18-18PM/fluro/{tile}*{exposure}*.tiff\")[0]\n",
    "        file2 = glob.glob(f\"../../mapping_2022-09-27.02-59-50PM/fluro/{tile}*{exposure}*.tiff\")[0]\n",
    "        img1 = mpimg.imread(file1)\n",
    "        img2 = mpimg.imread(file2)\n",
    "        fluor1[tile][exposure] = np.flip(img1[512:1536, 256:1792], axis=0)\n",
    "        fluor2[tile][exposure] = np.flip(img2[512:1536, 256:1792], axis=0)\n",
    "\n",
    "for tile in [\"0.0\", \"0.1\", \"1.0\", \"1.1\"]:\n",
    "    fluor3[tile] = {}\n",
    "    for exposure in exposures:\n",
    "        file3 = glob.glob(f\"../../mapping_2022-09-27.04-26-12PM/fluro/{tile}*{exposure}*.tiff\")[0]\n",
    "        img3 = mpimg.imread(file3)\n",
    "        fluor3[tile][exposure] = img3.T[512:1536, 256:1792]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pixelsize Fl 325nm/pixel\n",
    "\n",
    "Pixelsize IB 325nm/pixel\n",
    "\n",
    "Pixelsize IB 195(.312)nm/pixel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.25521e-07"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = \"../../mapping_2022-09-27.02-59-50PM/002.002/start_0.00050_ib.tif\"\n",
    "read = AdornedImage.load(path)\n",
    "read.metadata.binary_result.pixel_size.y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 636,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 2.20100851e+08      +0.j        ,\n",
       "        -2.76959985e+06+1265214.5011065j ],\n",
       "       [-3.09371041e+06-2115784.39522322j,\n",
       "        -3.81245498e+06 +891193.98399621j]])"
      ]
     },
     "execution_count": 636,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.fft.fftshift(np.fft.fft2(dict2[\"002.002\"][\"50\"][\"base\"]))[512:514, 768:770]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "921\n",
      "1382\n"
     ]
    }
   ],
   "source": [
    "print(int(1024/1.11111))\n",
    "print(int(1536/1.11111))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ib_fft = np.fft.fftshift(np.fft.fft2(dict2[\"002.002\"][\"50\"][\"base\"]))\n",
    "mat = np.ndarray((921, 1382), dtype=np.complex128)\n",
    "mat[:,:] = ib_fft[51:51+921, 461:461+1382]\n",
    "print(mat[461, 691])\n",
    "ib_crop = np.fft.ifft2(np.fft.ifftshift(mat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "614\n",
      "921\n"
     ]
    }
   ],
   "source": [
    "print(int(1024/1.66666666666))\n",
    "print(int(1536/1.666))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ib_fft = np.fft.fftshift(np.fft.fft2(dict2[\"002.002\"][\"50\"][\"base\"]))\n",
    "mat = np.ndarray((614, 922), dtype=np.complex128)\n",
    "mat[:,:] = ib_fft[205:205+614, 307:307+922]\n",
    "print(mat[307, 461])\n",
    "ib_crop = np.fft.ifft2(np.fft.ifftshift(mat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'np' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\phipo\\Documents\\GitHub\\PIE scope\\test\\tests\\check_ib_fl_xcorr.ipynb Cell 9\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/phipo/Documents/GitHub/PIE%20scope/test/tests/check_ib_fl_xcorr.ipynb#X14sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m ib_fft \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mfft\u001b[39m.\u001b[39mfftshift(np\u001b[39m.\u001b[39mfft\u001b[39m.\u001b[39mfft2(dict2[\u001b[39m\"\u001b[39m\u001b[39m002.002\u001b[39m\u001b[39m\"\u001b[39m][\u001b[39m\"\u001b[39m\u001b[39m50\u001b[39m\u001b[39m\"\u001b[39m][\u001b[39m\"\u001b[39m\u001b[39mbase\u001b[39m\u001b[39m\"\u001b[39m]))\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/phipo/Documents/GitHub/PIE%20scope/test/tests/check_ib_fl_xcorr.ipynb#X14sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m mat \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mndarray((\u001b[39m921\u001b[39m, \u001b[39m1382\u001b[39m), dtype\u001b[39m=\u001b[39mnp\u001b[39m.\u001b[39mcomplex128)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/phipo/Documents/GitHub/PIE%20scope/test/tests/check_ib_fl_xcorr.ipynb#X14sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m mat[:,:] \u001b[39m=\u001b[39m ib_fft[\u001b[39m205\u001b[39m:\u001b[39m205\u001b[39m\u001b[39m+\u001b[39m\u001b[39m614\u001b[39m, \u001b[39m307\u001b[39m:\u001b[39m307\u001b[39m\u001b[39m+\u001b[39m\u001b[39m922\u001b[39m]\n",
      "\u001b[1;31mNameError\u001b[0m: name 'np' is not defined"
     ]
    }
   ],
   "source": [
    "ib_fft = np.fft.fftshift(np.fft.fft2(dict2[\"002.002\"][\"50\"][\"base\"]))\n",
    "mat = np.ndarray((921, 1382), dtype=np.complex128)\n",
    "mat[:,:] = ib_fft[205:205+614, 307:307+922]\n",
    "print(mat[307, 461])\n",
    "ib_crop = np.fft.ifft2(np.fft.ifftshift(mat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(220100851+0j)\n"
     ]
    }
   ],
   "source": [
    "ib_fft = np.fft.fftshift(np.fft.fft2(dict2[\"002.002\"][\"50\"][\"base\"]))\n",
    "mat = np.ndarray((614, 922), dtype=np.complex128)\n",
    "mat[:,:] = ib_fft[205:205+614, 307:307+922]\n",
    "print(mat[307, 461])\n",
    "ib_crop = np.fft.ifft2(np.fft.ifftshift(mat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 696,
   "metadata": {},
   "outputs": [],
   "source": [
    "def circ_mask(image:np.ndarray, mask_radius:int):\n",
    "    zero_array = np.zeros(image.shape)\n",
    "    mask = cv2.circle(zero_array, (768, 512), mask_radius, (1, 1, 1), -1) \n",
    "    smooth_mask = ndi.gaussian_filter(mask, 1)\n",
    "    masked = image * smooth_mask\n",
    "    return masked\n",
    "\n",
    "\n",
    "def normalize(image:np.ndarray) -> np.ndarray:\n",
    "    mean, std = cv2.meanStdDev(image)\n",
    "    norm = (image - mean) / std\n",
    "    zero_array = np.zeros(norm.shape)\n",
    "    final_img = cv2.normalize(norm,  zero_array, 0, 1, cv2.NORM_MINMAX)\n",
    "    return final_img\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('fibsem')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "65b03cbd5232f89410b9b50b849bcc9b31e2f356061034afe49ef9e2ee6c4a26"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
